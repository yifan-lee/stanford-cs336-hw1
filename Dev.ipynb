{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from collections import defaultdict\n",
    "# import regex as re\n",
    "# from multiprocessing import Pool\n",
    "# from support.find_chunk_boundaries import find_chunk_boundaries\n",
    "# from memory_profiler import profile\n",
    "# import time, tracemalloc\n",
    "# from dataclasses import dataclass\n",
    "# from typing import BinaryIO, Iterable, Iterator\n",
    "# import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, einsum, reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4acb032",
   "metadata": {},
   "source": [
    "## Q2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "11d6a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(64, 128, 128, 3) # (batch, height, width, channel)\n",
    "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "be1b65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")\n",
    "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")\n",
    "dimmed_images = images_rearr * dim_value\n",
    "dimmed_images = einsum(\n",
    "    images, dim_by,\n",
    "    \"batch height width channel, dim_value -> batch dim_value height width channel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "ce9da0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 128, 128, 3])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimmed_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541b3d4",
   "metadata": {},
   "source": [
    "# Q 3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d12318ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, device: torch.device | None = None, dtype: torch.dtype | None = None):\n",
    "        super().__init__()\n",
    "        ## Construct a linear transformation module. This function should accept the following parameters:\n",
    "        self.in_features = in_features ## final dimension of the input\n",
    "        self.out_features = out_features ## final dimension of the output\n",
    "        self.device = device ## Device to store the parameters on\n",
    "        self.dtype = dtype ## Data type of the parameters\n",
    "\n",
    "        w = torch.empty(in_features, out_features)\n",
    "        std = torch.sqrt(torch.tensor(2.0/(in_features+out_features)))\n",
    "        self.weight = nn.Parameter(nn.init.trunc_normal_(w, mean=0.0, std=std.item(),a=-3*std.item(),b=3*std.item()))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ## Apply the linear transformation to the input\n",
    "        output = einsum(\n",
    "            self.weight, x,\n",
    "            \"in_dim out_dim, in_dim -> out_dim\"\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b05a99",
   "metadata": {},
   "source": [
    "# Q 3.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb550ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, device: torch.device | None = None, dtype: torch.dtype | None = None):\n",
    "        ## Construct an embedding module\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings ## Size of the vocabulary\n",
    "        self.embedding_dim = embedding_dim ## Dimension of the embedding vectors\n",
    "        self.device = device ## Device to store the parameters on\n",
    "        self.dtype = dtype ## Data type of the parameters\n",
    "        \n",
    "        w = torch.empty(num_embeddings, embedding_dim)\n",
    "        std = 1.0\n",
    "        self.weight = nn.Parameter(nn.init.trunc_normal_(w, mean=0.0, std=std,a=-3,b=3))\n",
    "    def forward(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
    "        ## Lookup the embedding vectors for the given token IDs.\n",
    "        return self.weight[token_ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06587e",
   "metadata": {},
   "source": [
    "# Q 3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "31176275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model: int, eps: float = 1e-5, device=None, dtype=None):\n",
    "        ## Construct the RMSNorm module.\n",
    "        super().__init__()\n",
    "        self.d_model = d_model ## Hidden dimension of the model\n",
    "        self.eps = eps ## Epsilon value for numerical stability\n",
    "        self.device = device ## Device to store the parameters on\n",
    "        self.dtype = dtype ## Data type of the parameters\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ## Process an input tensor of shape\n",
    "        \n",
    "        in_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        x_squaremean = reduce(\n",
    "            x**2, \"... d_model -> ... 1\", 'mean'\n",
    "        )\n",
    "        x_RMS = (x_squaremean+self.eps).sqrt()\n",
    "        result = x / x_RMS * self.weights\n",
    "        return result.to(in_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6984d27",
   "metadata": {},
   "source": [
    "# Q 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc353ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int | None = None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model ## Hidden dimension of the model\n",
    "        if d_ff is None:\n",
    "            q = round(d_model*8/3/64)\n",
    "            self.d_ff = q*64\n",
    "        else:\n",
    "            self.d_ff = d_ff\n",
    "        \n",
    "        self.w1_weight = nn.Parameter(torch.randn(self.d_ff, self.d_model))\n",
    "        self.w2_weight = nn.Parameter(torch.randn(self.d_model, self.d_ff))\n",
    "        self.w3_weight = nn.Parameter(torch.randn(self.d_ff, self.d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        w1x = einsum(\n",
    "            self.w1_weight, x,\n",
    "            \"d_ff d_model, ... d_model -> ... d_ff\"\n",
    "        )\n",
    "        w3x = einsum(\n",
    "            self.w3_weight, x,\n",
    "            \"d_ff d_model, ... d_model -> ... d_ff\"\n",
    "        )\n",
    "        SiLUw1x = w1x*torch.sigmoid(w1x)\n",
    "        part2 = SiLUw1x * w3x\n",
    "        result = einsum(\n",
    "            self.w2_weight, part2,\n",
    "            \"d_model d_ff, ... d_ff -> ... d_model\"\n",
    "        )\n",
    "        return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "a9a781ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8280, -1.0512],\n",
       "         [-0.9995,  0.6266],\n",
       "         [-0.2763,  1.1610]],\n",
       "\n",
       "        [[ 1.8855,  1.7226],\n",
       "         [-0.2060, -0.7651],\n",
       "         [ 0.1694,  1.8273]]])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 2\n",
    "d_ff = 3\n",
    "x = torch.randn(2, 3, d_model) \n",
    "w1_weight = torch.ones(d_ff, d_model)\n",
    "w2_weight = torch.ones(d_model, d_ff)\n",
    "w3_weight = torch.ones(d_ff, d_model)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "7bf71950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8792)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "94697768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8792, -1.8792, -1.8792],\n",
       "         [-0.3729, -0.3729, -0.3729],\n",
       "         [ 0.8847,  0.8847,  0.8847]],\n",
       "\n",
       "        [[ 3.6081,  3.6081,  3.6081],\n",
       "         [-0.9711, -0.9711, -0.9711],\n",
       "         [ 1.9966,  1.9966,  1.9966]]])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1x = einsum(\n",
    "            w1_weight, x,\n",
    "            \"d_ff d_model, ... d_model -> ... d_ff\"\n",
    "        )\n",
    "w1x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb486a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdfda749",
   "metadata": {},
   "source": [
    "# Q 3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21088daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8015,  1.2299, -0.0326,  1.3418],\n",
       "        [-0.2687, -0.0065,  0.4680,  0.7164]])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, heta: float, d_k: int, max_seq_len: int, device=None):\n",
    "        ## Construct the RoPE module and create buffers if needed.\n",
    "        super().__init__()\n",
    "        self.heta = heta ## $\\\\Theta$ value for the RoPE\n",
    "        self.d_k = d_k ## dimension of query and key vectors\n",
    "        self.max_seq_len = max_seq_len ## Maximum sequence length that will be inputted\n",
    "        self.device = device ## Device to store the buffer on\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        ## Process an input tensor of shape\n",
    "        \n",
    "        in_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        x_squaremean = reduce(\n",
    "            x**2, \"... d_model -> ... 1\", 'mean'\n",
    "        )\n",
    "        x_RMS = (x_squaremean+self.eps).sqrt()\n",
    "        result = x / x_RMS * self.weights\n",
    "        return result.to(in_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "77ac0aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化 RMSNorm\n",
    "rmsnorm = RMSNorm(d_model, eps)\n",
    "rmsnorm.weights.data.fill_(1.0)  # gamma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "16147faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7347,  1.1273, -0.0299,  1.2299],\n",
       "        [-0.2463, -0.0059,  0.4290,  0.6567]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前向计算\n",
    "y = rmsnorm(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "9ae5a520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8015,  1.2299, -0.0326,  1.3418])"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = x[0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "3ae931a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1235)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt((test**2).sum()/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "01520e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4036,  1.1004, -1.6200, -0.0424])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test/torch.sqrt((test**2).sum()/d_model+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f5c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 检查每个样本的 RMS\n",
    "rms = torch.sqrt(torch.mean(y**2, dim=-1))\n",
    "\n",
    "print(\"Input:\", x)\n",
    "print(\"Output:\", y)\n",
    "print(\"RMS per sample:\", rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b60f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b2b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
