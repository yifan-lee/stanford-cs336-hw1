{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd98ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4acb032",
   "metadata": {},
   "source": [
    "## 2.5 Experimenting with BPE Tokenizer Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd62680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpe(input_path: str, vocab_size: int, special_tokens: list[str]) -> tuple[dict[int, bytes], list[tuple[bytes, bytes]]]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4108944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt_as_str(input_path: str) -> str:\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def split_string(string: str, special_tokens: list[str]) -> list[str]:\n",
    "    pattern = \"|\".join(re.escape(tok) for tok in special_tokens)\n",
    "    return re.split(pattern,string)\n",
    "\n",
    "def get_tok_counts(string_list: list[str]) -> dict[str, int]:\n",
    "    counts = defaultdict(int)\n",
    "    for s in string_list:\n",
    "        tokens = re.finditer(PAT, s)\n",
    "        for m in tokens:\n",
    "            tok = m.group(0)\n",
    "            counts[tok] += 1\n",
    "    return counts\n",
    "\n",
    "def get_element_counts(counts: dict[str, int])-> dict[str, int]:\n",
    "    element_counts = defaultdict(int)\n",
    "    for token, count in counts.items():\n",
    "        elements = tuple([k for k in token])\n",
    "        element_counts[elements] += count\n",
    "    return element_counts\n",
    "\n",
    "def get_pair_counts(element_counts: dict[str, int]) -> dict[tuple[str,str], int]:\n",
    "    pair_counts = defaultdict(int)\n",
    "    for elements, count in element_counts.items():\n",
    "        for i in range(len(elements)-1):\n",
    "            pair_counts[(elements[i],elements[i+1])] += count\n",
    "    return pair_counts\n",
    "\n",
    "\n",
    "def update_element_counts(element_counts: dict[str, int], pair: tuple[str, str]) -> dict[str, int]:\n",
    "    new_element_counts = {}\n",
    "    for elements, counts in element_counts.items():\n",
    "        new_element = []\n",
    "        elements_len = len(elements)\n",
    "        index = 0\n",
    "        while index <= elements_len-1:\n",
    "            if (index < elements_len-1) and (elements[index] == pair[0]) and (elements[index+1] == pair[1]):\n",
    "                new_element.append(\"\".join(elements[index:index+2]))\n",
    "                index += 2\n",
    "            else:\n",
    "                new_element.append(elements[index])\n",
    "                index += 1\n",
    "        new_element_counts[tuple(new_element)] = counts\n",
    "    return new_element_counts  \n",
    "\n",
    "def initiate_vocab(special_tokens: list[str], unique_elements: set[str]) ->  dict[int, bytes]:\n",
    "    special_tokens_len = len(special_tokens)\n",
    "    vocab = {i: tok.encode(\"utf-8\") for i, tok in enumerate(special_tokens)}\n",
    "    for i, elem in enumerate(unique_elements, start=special_tokens_len):\n",
    "        vocab[i] = elem.encode(\"utf-8\")\n",
    "    return vocab     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a82139",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (2681849556.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[161]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef pre_tokenize(string: str,vocab_size: int,special_tokens: list[str]) -> dict[int, bytes],list[tuple[bytes, bytes]]:\u001b[39m\n                                                                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def pre_tokenize(string: str,vocab_size: int,special_tokens: list[str]) -> tuple[dict[int, bytes],list[tuple[bytes, bytes]]]:\n",
    "    merges = []\n",
    "    string_list = split_string(string, special_tokens)\n",
    "    counts = get_tok_counts(string_list)\n",
    "    element_counts = get_element_counts(counts)\n",
    "    unique_elements = set().union(*element_counts.keys())\n",
    "    vocab = initiate_vocab(special_tokens,unique_elements)\n",
    "    vocab_init_len = len(vocab)\n",
    "    while vocab_init_len<vocab_size:\n",
    "        pair_counts = get_pair_counts(element_counts)\n",
    "        pair = max(pair_counts, key=lambda k: (pair_counts[k], k))\n",
    "        merges.append(pair)\n",
    "        element_counts = update_element_counts(element_counts, pair)\n",
    "        vocab[vocab_init_len] = \"\".join(pair).encode(\"utf-8\")\n",
    "        vocab_init_len = len(vocab)\n",
    "    return vocab, merges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4e4f25a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['<|endoftext|>']\n",
    "input_path = fr'./data/test.txt'\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "epochs = 6\n",
    "vocab_size = 30\n",
    "string = \"hi. i'm yifan li. nice to meet you. this the what when here where\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66398de1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "336dfe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: b'<|endoftext|>',\n",
       " 1: b's',\n",
       " 2: b'c',\n",
       " 3: b't',\n",
       " 4: b'f',\n",
       " 5: b'y',\n",
       " 6: b'a',\n",
       " 7: b'o',\n",
       " 8: b'h',\n",
       " 9: b'n',\n",
       " 10: b'e',\n",
       " 11: b'l',\n",
       " 12: b'w',\n",
       " 13: b'r',\n",
       " 14: b'm',\n",
       " 15: b'i',\n",
       " 16: b'.',\n",
       " 17: b\"'\",\n",
       " 18: b'u',\n",
       " 19: b' ',\n",
       " 20: b'he',\n",
       " 21: b' w',\n",
       " 22: b' t',\n",
       " 23: b're',\n",
       " 24: b'here',\n",
       " 25: b'hi',\n",
       " 26: b' y',\n",
       " 27: b'ou',\n",
       " 28: b'ni',\n",
       " 29: b'nic'}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "967b43d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('h', 'e'), (' ', 'w'), (' ', 't'), ('r', 'e'), ('he', 're'), ('h', 'i')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9b4d8a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"hello! こんにちは!\"\n",
    "utf8_encoded = test_string.encode(\"utf-8\")\n",
    "utf8_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c6fb87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' ', 'w', 'h', 'e', 'r', 'e')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c50deb38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u don\\'t have to be scared of the loud dog, I\\'ll protect you\". The mole felt so safe with the little girl. She was very kind and the mole soon came to trust her. He leaned against her and she kept him safe. The mole had found his best friend.\\n<|endoftext|>\\nOnce upon a time, in a warm and sunny place, there was a big pit. A little boy named Tom liked to play near the pit. One day, Tom lost his red ball. He was very sad.\\nTom asked his friend, Sam, to help him search for the ball. They looked high and low, but they could not find the ball. Tom said, \"I think my ball fell into the pit.\"\\nSam and Tom went close to the pit. They were scared, but they wanted to find the red ball. They looked into the pit, but it was too dark to see. Tom said, \"We must go in and search for my ball.\"\\nThey went into the pit to search. It was dark and scary. They could not find the ball. They tried to get out, but the pit was too deep. Tom and Sam were stuck in the pit. They called for help, but no one could hear them. They were sad and scared, and they never got out of the pit.\\n<|endoftext|>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2658d073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('h', 'i'): 1,\n",
       "             ('.',): 3,\n",
       "             (' ', 'i'): 1,\n",
       "             (\"'\", 'm'): 1,\n",
       "             (' ', 'y', 'i', 'f', 'a', 'n'): 1,\n",
       "             (' ', 'l', 'i'): 1,\n",
       "             (' ', 'n', 'i', 'c', 'e'): 1,\n",
       "             (' ', 't', 'o'): 1,\n",
       "             (' ', 'm', 'e', 'e', 't'): 1,\n",
       "             (' ', 'y', 'o', 'u'): 1,\n",
       "             (' ', 't', 'h', 'i', 's'): 1,\n",
       "             (' ', 't', 'h', 'e'): 1,\n",
       "             (' ', 'w', 'h', 'a', 't'): 1,\n",
       "             (' ', 'w', 'h', 'e', 'n'): 1,\n",
       "             (' ', 'h', 'e', 'r', 'e'): 1,\n",
       "             (' ', 'w', 'h', 'e', 'r', 'e'): 1})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e30e9f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'hi': 2,\n",
       "             ' i': 1,\n",
       "             \"'m\": 1,\n",
       "             ' y': 2,\n",
       "             'yi': 1,\n",
       "             'if': 1,\n",
       "             'fa': 1,\n",
       "             'an': 1,\n",
       "             ' l': 1,\n",
       "             'li': 1,\n",
       "             ' n': 1,\n",
       "             'ni': 1,\n",
       "             'ic': 1,\n",
       "             'ce': 1,\n",
       "             ' t': 3,\n",
       "             'to': 1,\n",
       "             ' m': 1,\n",
       "             'me': 1,\n",
       "             'ee': 1,\n",
       "             'et': 1,\n",
       "             'yo': 1,\n",
       "             'ou': 1,\n",
       "             'th': 2,\n",
       "             'is': 1,\n",
       "             'he': 4,\n",
       "             ' w': 3,\n",
       "             'wh': 3,\n",
       "             'ha': 1,\n",
       "             'at': 1,\n",
       "             'en': 1,\n",
       "             ' h': 1,\n",
       "             'er': 2,\n",
       "             're': 2})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330713b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
