{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd98ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from collections import defaultdict\n",
    "# import regex as re\n",
    "# from multiprocessing import Pool\n",
    "# from support.find_chunk_boundaries import find_chunk_boundaries\n",
    "# from memory_profiler import profile\n",
    "# import time, tracemalloc\n",
    "# from dataclasses import dataclass\n",
    "# from typing import BinaryIO, Iterable, Iterator\n",
    "# import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, einsum, reduce, repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4acb032",
   "metadata": {},
   "source": [
    "## Q2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "11d6a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randn(64, 128, 128, 3) # (batch, height, width, channel)\n",
    "dim_by = torch.linspace(start=0.0, end=1.0, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "be1b65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_value = rearrange(dim_by, \"dim_value -> 1 dim_value 1 1 1\")\n",
    "images_rearr = rearrange(images, \"b height width channel -> b 1 height width channel\")\n",
    "dimmed_images = images_rearr * dim_value\n",
    "dimmed_images = einsum(\n",
    "    images, dim_by,\n",
    "    \"batch height width channel, dim_value -> batch dim_value height width channel\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "ce9da0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 128, 128, 3])"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimmed_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7541b3d4",
   "metadata": {},
   "source": [
    "# Q 3.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d12318ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, device: torch.device | None = None, dtype: torch.dtype | None = None):\n",
    "        super().__init__()\n",
    "        ## Construct a linear transformation module. This function should accept the following parameters:\n",
    "        self.in_features = in_features ## final dimension of the input\n",
    "        self.out_features = out_features ## final dimension of the output\n",
    "        self.device = device ## Device to store the parameters on\n",
    "        self.dtype = dtype ## Data type of the parameters\n",
    "\n",
    "        w = torch.empty(in_features, out_features)\n",
    "        std = torch.sqrt(torch.tensor(2.0/(in_features+out_features)))\n",
    "        self.weight = nn.Parameter(nn.init.trunc_normal_(w, mean=0.0, std=std.item(),a=-3*std.item(),b=3*std.item()))\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ## Apply the linear transformation to the input\n",
    "        output = einsum(\n",
    "            self.weight, x,\n",
    "            \"in_dim out_dim, in_dim -> out_dim\"\n",
    "        )\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b05a99",
   "metadata": {},
   "source": [
    "# Q 3.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb550ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, num_embeddings: int, embedding_dim: int, device: torch.device | None = None, dtype: torch.dtype | None = None):\n",
    "        ## Construct an embedding module\n",
    "        super().__init__()\n",
    "        self.num_embeddings = num_embeddings ## Size of the vocabulary\n",
    "        self.embedding_dim = embedding_dim ## Dimension of the embedding vectors\n",
    "        self.device = device ## Device to store the parameters on\n",
    "        self.dtype = dtype ## Data type of the parameters\n",
    "        \n",
    "        w = torch.empty(num_embeddings, embedding_dim)\n",
    "        std = 1.0\n",
    "        self.weight = nn.Parameter(nn.init.trunc_normal_(w, mean=0.0, std=std,a=-3,b=3))\n",
    "    def forward(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
    "        ## Lookup the embedding vectors for the given token IDs.\n",
    "        return self.weight[token_ids]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f06587e",
   "metadata": {},
   "source": [
    "# Q 3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "31176275",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, d_model: int, eps: float = 1e-5, device=None, dtype=None):\n",
    "        ## Construct the RMSNorm module.\n",
    "        super().__init__()\n",
    "        self.d_model = d_model ## Hidden dimension of the model\n",
    "        self.eps = eps ## Epsilon value for numerical stability\n",
    "        self.device = device ## Device to store the parameters on\n",
    "        self.dtype = dtype ## Data type of the parameters\n",
    "\n",
    "        self.weights = nn.Parameter(torch.ones(d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ## Process an input tensor of shape\n",
    "        \n",
    "        in_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        x_squaremean = reduce(\n",
    "            x**2, \"... d_model -> ... 1\", 'mean'\n",
    "        )\n",
    "        x_RMS = (x_squaremean+self.eps).sqrt()\n",
    "        result = x / x_RMS * self.weights\n",
    "        return result.to(in_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6984d27",
   "metadata": {},
   "source": [
    "# Q 3.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc353ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ff: int | None = None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model ## Hidden dimension of the model\n",
    "        if d_ff is None:\n",
    "            q = round(d_model*8/3/64)\n",
    "            self.d_ff = q*64\n",
    "        else:\n",
    "            self.d_ff = d_ff\n",
    "        \n",
    "        self.w1_weight = nn.Parameter(torch.randn(self.d_ff, self.d_model))\n",
    "        self.w2_weight = nn.Parameter(torch.randn(self.d_model, self.d_ff))\n",
    "        self.w3_weight = nn.Parameter(torch.randn(self.d_ff, self.d_model))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        w1x = einsum(\n",
    "            self.w1_weight, x,\n",
    "            \"d_ff d_model, ... d_model -> ... d_ff\"\n",
    "        )\n",
    "        w3x = einsum(\n",
    "            self.w3_weight, x,\n",
    "            \"d_ff d_model, ... d_model -> ... d_ff\"\n",
    "        )\n",
    "        SiLUw1x = w1x*torch.sigmoid(w1x)\n",
    "        part2 = SiLUw1x * w3x\n",
    "        result = einsum(\n",
    "            self.w2_weight, part2,\n",
    "            \"d_model d_ff, ... d_ff -> ... d_model\"\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "a9a781ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8280, -1.0512],\n",
       "         [-0.9995,  0.6266],\n",
       "         [-0.2763,  1.1610]],\n",
       "\n",
       "        [[ 1.8855,  1.7226],\n",
       "         [-0.2060, -0.7651],\n",
       "         [ 0.1694,  1.8273]]])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 2\n",
    "d_ff = 3\n",
    "x = torch.randn(2, 3, d_model) \n",
    "w1_weight = torch.ones(d_ff, d_model)\n",
    "w2_weight = torch.ones(d_model, d_ff)\n",
    "w3_weight = torch.ones(d_ff, d_model)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "7bf71950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8792)"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0,:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "94697768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8792, -1.8792, -1.8792],\n",
       "         [-0.3729, -0.3729, -0.3729],\n",
       "         [ 0.8847,  0.8847,  0.8847]],\n",
       "\n",
       "        [[ 3.6081,  3.6081,  3.6081],\n",
       "         [-0.9711, -0.9711, -0.9711],\n",
       "         [ 1.9966,  1.9966,  1.9966]]])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1x = einsum(\n",
    "            w1_weight, x,\n",
    "            \"d_ff d_model, ... d_model -> ... d_ff\"\n",
    "        )\n",
    "w1x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfda749",
   "metadata": {},
   "source": [
    "# Q 3.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "21088daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8015,  1.2299, -0.0326,  1.3418],\n",
       "        [-0.2687, -0.0065,  0.4680,  0.7164]])"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RotaryPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, theta: float, d_k: int, max_seq_len: int, device: torch.device | None = None):\n",
    "        ## Construct the RoPE module and create buffers if needed.\n",
    "        super().__init__()\n",
    "        self.theta = theta ## $\\\\Theta$ value for the RoPE\n",
    "        self.d_k = d_k ## dimension of query and key vectors\n",
    "        self.max_seq_len = max_seq_len ## Maximum sequence length that will be inputted\n",
    "        self.device = device ## Device to store the buffer on\n",
    "\n",
    "        theta_ik = torch.Tensor([[i/(self.theta**((2*k-1)/self.d_k)) for k in range(1,self.d_k//2+2)] for i in range(self.max_seq_len)])\n",
    "        sin = torch.sin(theta_ik)\n",
    "        cos = torch.cos(theta_ik)\n",
    "        \n",
    "        self.register_buffer(\"sin\", sin, persistent=False)\n",
    "        self.register_buffer(\"cos\", cos, persistent=False)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, token_positions: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        sin_expend = self.sin[token_positions]\n",
    "        cos_expend = self.cos[token_positions]\n",
    "\n",
    "        x_even = x[...,::2]\n",
    "        x_odd = x[...,1::2]\n",
    "\n",
    "        y_even = x_even*cos_expend-x_odd*sin_expend\n",
    "        y_odd = x_odd*sin_expend+x_even*cos_expend\n",
    "        y = rearrange(torch.stack([y_even, y_odd], dim=-1), '... s d two -> ... s (two d)')\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "d6eff21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 10000\n",
    "d_k = 4\n",
    "max_seq_len = 100\n",
    "seq_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "efd9741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,2,3]\n",
    "x[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "c8783da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e-02],\n",
       "        [2.0000e+00, 2.0000e-02],\n",
       "        [3.0000e+00, 3.0000e-02],\n",
       "        [4.0000e+00, 4.0000e-02],\n",
       "        [5.0000e+00, 5.0000e-02],\n",
       "        [6.0000e+00, 6.0000e-02],\n",
       "        [7.0000e+00, 7.0000e-02],\n",
       "        [8.0000e+00, 8.0000e-02],\n",
       "        [9.0000e+00, 9.0000e-02],\n",
       "        [1.0000e+01, 1.0000e-01],\n",
       "        [1.1000e+01, 1.1000e-01],\n",
       "        [1.2000e+01, 1.2000e-01],\n",
       "        [1.3000e+01, 1.3000e-01],\n",
       "        [1.4000e+01, 1.4000e-01],\n",
       "        [1.5000e+01, 1.5000e-01],\n",
       "        [1.6000e+01, 1.6000e-01],\n",
       "        [1.7000e+01, 1.7000e-01],\n",
       "        [1.8000e+01, 1.8000e-01],\n",
       "        [1.9000e+01, 1.9000e-01],\n",
       "        [2.0000e+01, 2.0000e-01],\n",
       "        [2.1000e+01, 2.1000e-01],\n",
       "        [2.2000e+01, 2.2000e-01],\n",
       "        [2.3000e+01, 2.3000e-01],\n",
       "        [2.4000e+01, 2.4000e-01],\n",
       "        [2.5000e+01, 2.5000e-01],\n",
       "        [2.6000e+01, 2.6000e-01],\n",
       "        [2.7000e+01, 2.7000e-01],\n",
       "        [2.8000e+01, 2.8000e-01],\n",
       "        [2.9000e+01, 2.9000e-01],\n",
       "        [3.0000e+01, 3.0000e-01],\n",
       "        [3.1000e+01, 3.1000e-01],\n",
       "        [3.2000e+01, 3.2000e-01],\n",
       "        [3.3000e+01, 3.3000e-01],\n",
       "        [3.4000e+01, 3.4000e-01],\n",
       "        [3.5000e+01, 3.5000e-01],\n",
       "        [3.6000e+01, 3.6000e-01],\n",
       "        [3.7000e+01, 3.7000e-01],\n",
       "        [3.8000e+01, 3.8000e-01],\n",
       "        [3.9000e+01, 3.9000e-01],\n",
       "        [4.0000e+01, 4.0000e-01],\n",
       "        [4.1000e+01, 4.1000e-01],\n",
       "        [4.2000e+01, 4.2000e-01],\n",
       "        [4.3000e+01, 4.3000e-01],\n",
       "        [4.4000e+01, 4.4000e-01],\n",
       "        [4.5000e+01, 4.5000e-01],\n",
       "        [4.6000e+01, 4.6000e-01],\n",
       "        [4.7000e+01, 4.7000e-01],\n",
       "        [4.8000e+01, 4.8000e-01],\n",
       "        [4.9000e+01, 4.9000e-01],\n",
       "        [5.0000e+01, 5.0000e-01],\n",
       "        [5.1000e+01, 5.1000e-01],\n",
       "        [5.2000e+01, 5.2000e-01],\n",
       "        [5.3000e+01, 5.3000e-01],\n",
       "        [5.4000e+01, 5.4000e-01],\n",
       "        [5.5000e+01, 5.5000e-01],\n",
       "        [5.6000e+01, 5.6000e-01],\n",
       "        [5.7000e+01, 5.7000e-01],\n",
       "        [5.8000e+01, 5.8000e-01],\n",
       "        [5.9000e+01, 5.9000e-01],\n",
       "        [6.0000e+01, 6.0000e-01],\n",
       "        [6.1000e+01, 6.1000e-01],\n",
       "        [6.2000e+01, 6.2000e-01],\n",
       "        [6.3000e+01, 6.3000e-01],\n",
       "        [6.4000e+01, 6.4000e-01],\n",
       "        [6.5000e+01, 6.5000e-01],\n",
       "        [6.6000e+01, 6.6000e-01],\n",
       "        [6.7000e+01, 6.7000e-01],\n",
       "        [6.8000e+01, 6.8000e-01],\n",
       "        [6.9000e+01, 6.9000e-01],\n",
       "        [7.0000e+01, 7.0000e-01],\n",
       "        [7.1000e+01, 7.1000e-01],\n",
       "        [7.2000e+01, 7.2000e-01],\n",
       "        [7.3000e+01, 7.3000e-01],\n",
       "        [7.4000e+01, 7.4000e-01],\n",
       "        [7.5000e+01, 7.5000e-01],\n",
       "        [7.6000e+01, 7.6000e-01],\n",
       "        [7.7000e+01, 7.7000e-01],\n",
       "        [7.8000e+01, 7.8000e-01],\n",
       "        [7.9000e+01, 7.9000e-01],\n",
       "        [8.0000e+01, 8.0000e-01],\n",
       "        [8.1000e+01, 8.1000e-01],\n",
       "        [8.2000e+01, 8.2000e-01],\n",
       "        [8.3000e+01, 8.3000e-01],\n",
       "        [8.4000e+01, 8.4000e-01],\n",
       "        [8.5000e+01, 8.5000e-01],\n",
       "        [8.6000e+01, 8.6000e-01],\n",
       "        [8.7000e+01, 8.7000e-01],\n",
       "        [8.8000e+01, 8.8000e-01],\n",
       "        [8.9000e+01, 8.9000e-01],\n",
       "        [9.0000e+01, 9.0000e-01],\n",
       "        [9.1000e+01, 9.1000e-01],\n",
       "        [9.2000e+01, 9.2000e-01],\n",
       "        [9.3000e+01, 9.3000e-01],\n",
       "        [9.4000e+01, 9.4000e-01],\n",
       "        [9.5000e+01, 9.5000e-01],\n",
       "        [9.6000e+01, 9.6000e-01],\n",
       "        [9.7000e+01, 9.7000e-01],\n",
       "        [9.8000e+01, 9.8000e-01],\n",
       "        [9.9000e+01, 9.9000e-01]])"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_index = torch.arange(d_k // 2, dtype=torch.float32)\n",
    "position_index = torch.arange(max_seq_len, dtype=torch.float32)\n",
    "theta_inv_index = theta**(-2*dim_index/d_k)\n",
    "theta_ik = einsum(\n",
    "    position_index, theta_inv_index,\n",
    "    \"s, d -> s d\"\n",
    ")\n",
    "theta_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "7f884661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e-02],\n",
       "        [2.0000e+00, 2.0000e-02],\n",
       "        [3.0000e+00, 3.0000e-02],\n",
       "        [4.0000e+00, 4.0000e-02],\n",
       "        [5.0000e+00, 5.0000e-02],\n",
       "        [6.0000e+00, 6.0000e-02],\n",
       "        [7.0000e+00, 7.0000e-02],\n",
       "        [8.0000e+00, 8.0000e-02],\n",
       "        [9.0000e+00, 9.0000e-02],\n",
       "        [1.0000e+01, 1.0000e-01],\n",
       "        [1.1000e+01, 1.1000e-01],\n",
       "        [1.2000e+01, 1.2000e-01],\n",
       "        [1.3000e+01, 1.3000e-01],\n",
       "        [1.4000e+01, 1.4000e-01],\n",
       "        [1.5000e+01, 1.5000e-01],\n",
       "        [1.6000e+01, 1.6000e-01],\n",
       "        [1.7000e+01, 1.7000e-01],\n",
       "        [1.8000e+01, 1.8000e-01],\n",
       "        [1.9000e+01, 1.9000e-01],\n",
       "        [2.0000e+01, 2.0000e-01],\n",
       "        [2.1000e+01, 2.1000e-01],\n",
       "        [2.2000e+01, 2.2000e-01],\n",
       "        [2.3000e+01, 2.3000e-01],\n",
       "        [2.4000e+01, 2.4000e-01],\n",
       "        [2.5000e+01, 2.5000e-01],\n",
       "        [2.6000e+01, 2.6000e-01],\n",
       "        [2.7000e+01, 2.7000e-01],\n",
       "        [2.8000e+01, 2.8000e-01],\n",
       "        [2.9000e+01, 2.9000e-01],\n",
       "        [3.0000e+01, 3.0000e-01],\n",
       "        [3.1000e+01, 3.1000e-01],\n",
       "        [3.2000e+01, 3.2000e-01],\n",
       "        [3.3000e+01, 3.3000e-01],\n",
       "        [3.4000e+01, 3.4000e-01],\n",
       "        [3.5000e+01, 3.5000e-01],\n",
       "        [3.6000e+01, 3.6000e-01],\n",
       "        [3.7000e+01, 3.7000e-01],\n",
       "        [3.8000e+01, 3.8000e-01],\n",
       "        [3.9000e+01, 3.9000e-01],\n",
       "        [4.0000e+01, 4.0000e-01],\n",
       "        [4.1000e+01, 4.1000e-01],\n",
       "        [4.2000e+01, 4.2000e-01],\n",
       "        [4.3000e+01, 4.3000e-01],\n",
       "        [4.4000e+01, 4.4000e-01],\n",
       "        [4.5000e+01, 4.5000e-01],\n",
       "        [4.6000e+01, 4.6000e-01],\n",
       "        [4.7000e+01, 4.7000e-01],\n",
       "        [4.8000e+01, 4.8000e-01],\n",
       "        [4.9000e+01, 4.9000e-01],\n",
       "        [5.0000e+01, 5.0000e-01],\n",
       "        [5.1000e+01, 5.1000e-01],\n",
       "        [5.2000e+01, 5.2000e-01],\n",
       "        [5.3000e+01, 5.3000e-01],\n",
       "        [5.4000e+01, 5.4000e-01],\n",
       "        [5.5000e+01, 5.5000e-01],\n",
       "        [5.6000e+01, 5.6000e-01],\n",
       "        [5.7000e+01, 5.7000e-01],\n",
       "        [5.8000e+01, 5.8000e-01],\n",
       "        [5.9000e+01, 5.9000e-01],\n",
       "        [6.0000e+01, 6.0000e-01],\n",
       "        [6.1000e+01, 6.1000e-01],\n",
       "        [6.2000e+01, 6.2000e-01],\n",
       "        [6.3000e+01, 6.3000e-01],\n",
       "        [6.4000e+01, 6.4000e-01],\n",
       "        [6.5000e+01, 6.5000e-01],\n",
       "        [6.6000e+01, 6.6000e-01],\n",
       "        [6.7000e+01, 6.7000e-01],\n",
       "        [6.8000e+01, 6.8000e-01],\n",
       "        [6.9000e+01, 6.9000e-01],\n",
       "        [7.0000e+01, 7.0000e-01],\n",
       "        [7.1000e+01, 7.1000e-01],\n",
       "        [7.2000e+01, 7.2000e-01],\n",
       "        [7.3000e+01, 7.3000e-01],\n",
       "        [7.4000e+01, 7.4000e-01],\n",
       "        [7.5000e+01, 7.5000e-01],\n",
       "        [7.6000e+01, 7.6000e-01],\n",
       "        [7.7000e+01, 7.7000e-01],\n",
       "        [7.8000e+01, 7.8000e-01],\n",
       "        [7.9000e+01, 7.9000e-01],\n",
       "        [8.0000e+01, 8.0000e-01],\n",
       "        [8.1000e+01, 8.1000e-01],\n",
       "        [8.2000e+01, 8.2000e-01],\n",
       "        [8.3000e+01, 8.3000e-01],\n",
       "        [8.4000e+01, 8.4000e-01],\n",
       "        [8.5000e+01, 8.5000e-01],\n",
       "        [8.6000e+01, 8.6000e-01],\n",
       "        [8.7000e+01, 8.7000e-01],\n",
       "        [8.8000e+01, 8.8000e-01],\n",
       "        [8.9000e+01, 8.9000e-01],\n",
       "        [9.0000e+01, 9.0000e-01],\n",
       "        [9.1000e+01, 9.1000e-01],\n",
       "        [9.2000e+01, 9.2000e-01],\n",
       "        [9.3000e+01, 9.3000e-01],\n",
       "        [9.4000e+01, 9.4000e-01],\n",
       "        [9.5000e+01, 9.5000e-01],\n",
       "        [9.6000e+01, 9.6000e-01],\n",
       "        [9.7000e+01, 9.7000e-01],\n",
       "        [9.8000e+01, 9.8000e-01],\n",
       "        [9.9000e+01, 9.9000e-01]])"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_ik = torch.Tensor([[i/(theta**((2*k-2)/d_k)) for k in range(1,d_k//2+1)] for i in range(max_seq_len)])\n",
    "sin = torch.sin(theta_ik)\n",
    "cos = torch.cos(theta_ik)\n",
    "theta_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "108d830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_index = torch.arange(0, d_k, 2, dtype=torch.float32)\n",
    "inv_freq = theta ** (-dim_index / d_k)\n",
    "positions = torch.arange(\n",
    "            max_seq_len, dtype=torch.float32\n",
    "        )\n",
    "freqs = einsum(\n",
    "            positions, inv_freq, \"max_seq_len, d_k_2 -> max_seq_len d_k_2\"\n",
    "        ) \n",
    "cos_cached = freqs.cos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "e7341b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e-02],\n",
       "        [2.0000e+00, 2.0000e-02],\n",
       "        [3.0000e+00, 3.0000e-02],\n",
       "        [4.0000e+00, 4.0000e-02],\n",
       "        [5.0000e+00, 5.0000e-02],\n",
       "        [6.0000e+00, 6.0000e-02],\n",
       "        [7.0000e+00, 7.0000e-02],\n",
       "        [8.0000e+00, 8.0000e-02],\n",
       "        [9.0000e+00, 9.0000e-02],\n",
       "        [1.0000e+01, 1.0000e-01],\n",
       "        [1.1000e+01, 1.1000e-01],\n",
       "        [1.2000e+01, 1.2000e-01],\n",
       "        [1.3000e+01, 1.3000e-01],\n",
       "        [1.4000e+01, 1.4000e-01],\n",
       "        [1.5000e+01, 1.5000e-01],\n",
       "        [1.6000e+01, 1.6000e-01],\n",
       "        [1.7000e+01, 1.7000e-01],\n",
       "        [1.8000e+01, 1.8000e-01],\n",
       "        [1.9000e+01, 1.9000e-01],\n",
       "        [2.0000e+01, 2.0000e-01],\n",
       "        [2.1000e+01, 2.1000e-01],\n",
       "        [2.2000e+01, 2.2000e-01],\n",
       "        [2.3000e+01, 2.3000e-01],\n",
       "        [2.4000e+01, 2.4000e-01],\n",
       "        [2.5000e+01, 2.5000e-01],\n",
       "        [2.6000e+01, 2.6000e-01],\n",
       "        [2.7000e+01, 2.7000e-01],\n",
       "        [2.8000e+01, 2.8000e-01],\n",
       "        [2.9000e+01, 2.9000e-01],\n",
       "        [3.0000e+01, 3.0000e-01],\n",
       "        [3.1000e+01, 3.1000e-01],\n",
       "        [3.2000e+01, 3.2000e-01],\n",
       "        [3.3000e+01, 3.3000e-01],\n",
       "        [3.4000e+01, 3.4000e-01],\n",
       "        [3.5000e+01, 3.5000e-01],\n",
       "        [3.6000e+01, 3.6000e-01],\n",
       "        [3.7000e+01, 3.7000e-01],\n",
       "        [3.8000e+01, 3.8000e-01],\n",
       "        [3.9000e+01, 3.9000e-01],\n",
       "        [4.0000e+01, 4.0000e-01],\n",
       "        [4.1000e+01, 4.1000e-01],\n",
       "        [4.2000e+01, 4.2000e-01],\n",
       "        [4.3000e+01, 4.3000e-01],\n",
       "        [4.4000e+01, 4.4000e-01],\n",
       "        [4.5000e+01, 4.5000e-01],\n",
       "        [4.6000e+01, 4.6000e-01],\n",
       "        [4.7000e+01, 4.7000e-01],\n",
       "        [4.8000e+01, 4.8000e-01],\n",
       "        [4.9000e+01, 4.9000e-01],\n",
       "        [5.0000e+01, 5.0000e-01],\n",
       "        [5.1000e+01, 5.1000e-01],\n",
       "        [5.2000e+01, 5.2000e-01],\n",
       "        [5.3000e+01, 5.3000e-01],\n",
       "        [5.4000e+01, 5.4000e-01],\n",
       "        [5.5000e+01, 5.5000e-01],\n",
       "        [5.6000e+01, 5.6000e-01],\n",
       "        [5.7000e+01, 5.7000e-01],\n",
       "        [5.8000e+01, 5.8000e-01],\n",
       "        [5.9000e+01, 5.9000e-01],\n",
       "        [6.0000e+01, 6.0000e-01],\n",
       "        [6.1000e+01, 6.1000e-01],\n",
       "        [6.2000e+01, 6.2000e-01],\n",
       "        [6.3000e+01, 6.3000e-01],\n",
       "        [6.4000e+01, 6.4000e-01],\n",
       "        [6.5000e+01, 6.5000e-01],\n",
       "        [6.6000e+01, 6.6000e-01],\n",
       "        [6.7000e+01, 6.7000e-01],\n",
       "        [6.8000e+01, 6.8000e-01],\n",
       "        [6.9000e+01, 6.9000e-01],\n",
       "        [7.0000e+01, 7.0000e-01],\n",
       "        [7.1000e+01, 7.1000e-01],\n",
       "        [7.2000e+01, 7.2000e-01],\n",
       "        [7.3000e+01, 7.3000e-01],\n",
       "        [7.4000e+01, 7.4000e-01],\n",
       "        [7.5000e+01, 7.5000e-01],\n",
       "        [7.6000e+01, 7.6000e-01],\n",
       "        [7.7000e+01, 7.7000e-01],\n",
       "        [7.8000e+01, 7.8000e-01],\n",
       "        [7.9000e+01, 7.9000e-01],\n",
       "        [8.0000e+01, 8.0000e-01],\n",
       "        [8.1000e+01, 8.1000e-01],\n",
       "        [8.2000e+01, 8.2000e-01],\n",
       "        [8.3000e+01, 8.3000e-01],\n",
       "        [8.4000e+01, 8.4000e-01],\n",
       "        [8.5000e+01, 8.5000e-01],\n",
       "        [8.6000e+01, 8.6000e-01],\n",
       "        [8.7000e+01, 8.7000e-01],\n",
       "        [8.8000e+01, 8.8000e-01],\n",
       "        [8.9000e+01, 8.9000e-01],\n",
       "        [9.0000e+01, 9.0000e-01],\n",
       "        [9.1000e+01, 9.1000e-01],\n",
       "        [9.2000e+01, 9.2000e-01],\n",
       "        [9.3000e+01, 9.3000e-01],\n",
       "        [9.4000e+01, 9.4000e-01],\n",
       "        [9.5000e+01, 9.5000e-01],\n",
       "        [9.6000e+01, 9.6000e-01],\n",
       "        [9.7000e+01, 9.7000e-01],\n",
       "        [9.8000e+01, 9.8000e-01],\n",
       "        [9.9000e+01, 9.9000e-01]])"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "82d2d9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 1.0000e-02],\n",
       "        [2.0000e+00, 2.0000e-02],\n",
       "        [3.0000e+00, 3.0000e-02],\n",
       "        [4.0000e+00, 4.0000e-02],\n",
       "        [5.0000e+00, 5.0000e-02],\n",
       "        [6.0000e+00, 6.0000e-02],\n",
       "        [7.0000e+00, 7.0000e-02],\n",
       "        [8.0000e+00, 8.0000e-02],\n",
       "        [9.0000e+00, 9.0000e-02],\n",
       "        [1.0000e+01, 1.0000e-01],\n",
       "        [1.1000e+01, 1.1000e-01],\n",
       "        [1.2000e+01, 1.2000e-01],\n",
       "        [1.3000e+01, 1.3000e-01],\n",
       "        [1.4000e+01, 1.4000e-01],\n",
       "        [1.5000e+01, 1.5000e-01],\n",
       "        [1.6000e+01, 1.6000e-01],\n",
       "        [1.7000e+01, 1.7000e-01],\n",
       "        [1.8000e+01, 1.8000e-01],\n",
       "        [1.9000e+01, 1.9000e-01],\n",
       "        [2.0000e+01, 2.0000e-01],\n",
       "        [2.1000e+01, 2.1000e-01],\n",
       "        [2.2000e+01, 2.2000e-01],\n",
       "        [2.3000e+01, 2.3000e-01],\n",
       "        [2.4000e+01, 2.4000e-01],\n",
       "        [2.5000e+01, 2.5000e-01],\n",
       "        [2.6000e+01, 2.6000e-01],\n",
       "        [2.7000e+01, 2.7000e-01],\n",
       "        [2.8000e+01, 2.8000e-01],\n",
       "        [2.9000e+01, 2.9000e-01],\n",
       "        [3.0000e+01, 3.0000e-01],\n",
       "        [3.1000e+01, 3.1000e-01],\n",
       "        [3.2000e+01, 3.2000e-01],\n",
       "        [3.3000e+01, 3.3000e-01],\n",
       "        [3.4000e+01, 3.4000e-01],\n",
       "        [3.5000e+01, 3.5000e-01],\n",
       "        [3.6000e+01, 3.6000e-01],\n",
       "        [3.7000e+01, 3.7000e-01],\n",
       "        [3.8000e+01, 3.8000e-01],\n",
       "        [3.9000e+01, 3.9000e-01],\n",
       "        [4.0000e+01, 4.0000e-01],\n",
       "        [4.1000e+01, 4.1000e-01],\n",
       "        [4.2000e+01, 4.2000e-01],\n",
       "        [4.3000e+01, 4.3000e-01],\n",
       "        [4.4000e+01, 4.4000e-01],\n",
       "        [4.5000e+01, 4.5000e-01],\n",
       "        [4.6000e+01, 4.6000e-01],\n",
       "        [4.7000e+01, 4.7000e-01],\n",
       "        [4.8000e+01, 4.8000e-01],\n",
       "        [4.9000e+01, 4.9000e-01],\n",
       "        [5.0000e+01, 5.0000e-01],\n",
       "        [5.1000e+01, 5.1000e-01],\n",
       "        [5.2000e+01, 5.2000e-01],\n",
       "        [5.3000e+01, 5.3000e-01],\n",
       "        [5.4000e+01, 5.4000e-01],\n",
       "        [5.5000e+01, 5.5000e-01],\n",
       "        [5.6000e+01, 5.6000e-01],\n",
       "        [5.7000e+01, 5.7000e-01],\n",
       "        [5.8000e+01, 5.8000e-01],\n",
       "        [5.9000e+01, 5.9000e-01],\n",
       "        [6.0000e+01, 6.0000e-01],\n",
       "        [6.1000e+01, 6.1000e-01],\n",
       "        [6.2000e+01, 6.2000e-01],\n",
       "        [6.3000e+01, 6.3000e-01],\n",
       "        [6.4000e+01, 6.4000e-01],\n",
       "        [6.5000e+01, 6.5000e-01],\n",
       "        [6.6000e+01, 6.6000e-01],\n",
       "        [6.7000e+01, 6.7000e-01],\n",
       "        [6.8000e+01, 6.8000e-01],\n",
       "        [6.9000e+01, 6.9000e-01],\n",
       "        [7.0000e+01, 7.0000e-01],\n",
       "        [7.1000e+01, 7.1000e-01],\n",
       "        [7.2000e+01, 7.2000e-01],\n",
       "        [7.3000e+01, 7.3000e-01],\n",
       "        [7.4000e+01, 7.4000e-01],\n",
       "        [7.5000e+01, 7.5000e-01],\n",
       "        [7.6000e+01, 7.6000e-01],\n",
       "        [7.7000e+01, 7.7000e-01],\n",
       "        [7.8000e+01, 7.8000e-01],\n",
       "        [7.9000e+01, 7.9000e-01],\n",
       "        [8.0000e+01, 8.0000e-01],\n",
       "        [8.1000e+01, 8.1000e-01],\n",
       "        [8.2000e+01, 8.2000e-01],\n",
       "        [8.3000e+01, 8.3000e-01],\n",
       "        [8.4000e+01, 8.4000e-01],\n",
       "        [8.5000e+01, 8.5000e-01],\n",
       "        [8.6000e+01, 8.6000e-01],\n",
       "        [8.7000e+01, 8.7000e-01],\n",
       "        [8.8000e+01, 8.8000e-01],\n",
       "        [8.9000e+01, 8.9000e-01],\n",
       "        [9.0000e+01, 9.0000e-01],\n",
       "        [9.1000e+01, 9.1000e-01],\n",
       "        [9.2000e+01, 9.2000e-01],\n",
       "        [9.3000e+01, 9.3000e-01],\n",
       "        [9.4000e+01, 9.4000e-01],\n",
       "        [9.5000e+01, 9.5000e-01],\n",
       "        [9.6000e+01, 9.6000e-01],\n",
       "        [9.7000e+01, 9.7000e-01],\n",
       "        [9.8000e+01, 9.8000e-01],\n",
       "        [9.9000e+01, 9.9000e-01]])"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_ik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "3d32fc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 4]), torch.Size([3])]"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12]\n",
    "]\n",
    "x = torch.tensor(data)\n",
    "data = [2,0,1]\n",
    "position = torch.tensor(data)\n",
    "[x.shape, position.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "123379ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape[:-1]==position.shape[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "2369f034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5827,  2.1588,  2.9920,  4.0060],\n",
       "        [ 5.0000,  6.0000,  7.0000,  8.0000],\n",
       "        [ 7.9567, 10.8485, 10.9880, 12.0110]])"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_expend = sin[position]\n",
    "cos_expend = cos[position]\n",
    "\n",
    "x_even = x[...,::2]\n",
    "x_odd = x[...,1::2]\n",
    "\n",
    "y_even = x_even*cos_expend-x_odd*sin_expend\n",
    "y_odd = x_even*sin_expend+x_odd*cos_expend\n",
    "y = rearrange(torch.stack([y_even, y_odd], dim=-1), '... s d two -> ... s (d two)')\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "dd0da07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5827), tensor(2.1588), tensor(2.9920), tensor(4.0060)]"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_index = 0\n",
    "posi = position[seq_index]\n",
    "x_sub = x[seq_index,:]\n",
    "[x_sub[0]*cos[posi,0]-x_sub[1]*sin[posi,0],x_sub[0]*sin[posi,0]+x_sub[1]*cos[posi,0],x_sub[2]*cos[posi,1]-x_sub[3]*sin[posi,1],x_sub[2]*sin[posi,1]+x_sub[3]*cos[posi,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "04ee0ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5827,  2.9920],\n",
       "        [ 5.0000,  7.0000],\n",
       "        [ 7.9567, 10.9880]])"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "23a49ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2])"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.stack([y_even, y_odd], dim=-1)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "1279c2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5827,  2.1588],\n",
       "         [ 2.9920,  4.0060]],\n",
       "\n",
       "        [[ 5.0000,  6.0000],\n",
       "         [ 7.0000,  8.0000]],\n",
       "\n",
       "        [[ 7.9567, 10.8485],\n",
       "         [10.9880, 12.0110]]])"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "5b4868d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1987, 0.0020],\n",
       "        [0.0000, 0.0000],\n",
       "        [0.0998, 0.0010]])"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin_expend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "54c2ade8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1987)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sin[posi,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "13cbbbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9950)"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "34470571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000],\n",
       "        [ 0.9950,  1.0000],\n",
       "        [ 0.9801,  1.0000],\n",
       "        [ 0.9553,  1.0000],\n",
       "        [ 0.9211,  1.0000],\n",
       "        [ 0.8776,  1.0000],\n",
       "        [ 0.8253,  1.0000],\n",
       "        [ 0.7648,  1.0000],\n",
       "        [ 0.6967,  1.0000],\n",
       "        [ 0.6216,  1.0000],\n",
       "        [ 0.5403,  0.9999],\n",
       "        [ 0.4536,  0.9999],\n",
       "        [ 0.3624,  0.9999],\n",
       "        [ 0.2675,  0.9999],\n",
       "        [ 0.1700,  0.9999],\n",
       "        [ 0.0707,  0.9999],\n",
       "        [-0.0292,  0.9999],\n",
       "        [-0.1288,  0.9999],\n",
       "        [-0.2272,  0.9998],\n",
       "        [-0.3233,  0.9998],\n",
       "        [-0.4161,  0.9998],\n",
       "        [-0.5048,  0.9998],\n",
       "        [-0.5885,  0.9998],\n",
       "        [-0.6663,  0.9997],\n",
       "        [-0.7374,  0.9997],\n",
       "        [-0.8011,  0.9997],\n",
       "        [-0.8569,  0.9997],\n",
       "        [-0.9041,  0.9996],\n",
       "        [-0.9422,  0.9996],\n",
       "        [-0.9710,  0.9996],\n",
       "        [-0.9900,  0.9996],\n",
       "        [-0.9991,  0.9995],\n",
       "        [-0.9983,  0.9995],\n",
       "        [-0.9875,  0.9995],\n",
       "        [-0.9668,  0.9994],\n",
       "        [-0.9365,  0.9994],\n",
       "        [-0.8968,  0.9994],\n",
       "        [-0.8481,  0.9993],\n",
       "        [-0.7910,  0.9993],\n",
       "        [-0.7259,  0.9992],\n",
       "        [-0.6536,  0.9992],\n",
       "        [-0.5748,  0.9992],\n",
       "        [-0.4903,  0.9991],\n",
       "        [-0.4008,  0.9991],\n",
       "        [-0.3073,  0.9990],\n",
       "        [-0.2108,  0.9990],\n",
       "        [-0.1122,  0.9989],\n",
       "        [-0.0124,  0.9989],\n",
       "        [ 0.0875,  0.9988],\n",
       "        [ 0.1865,  0.9988],\n",
       "        [ 0.2837,  0.9988],\n",
       "        [ 0.3780,  0.9987],\n",
       "        [ 0.4685,  0.9986],\n",
       "        [ 0.5544,  0.9986],\n",
       "        [ 0.6347,  0.9985],\n",
       "        [ 0.7087,  0.9985],\n",
       "        [ 0.7756,  0.9984],\n",
       "        [ 0.8347,  0.9984],\n",
       "        [ 0.8855,  0.9983],\n",
       "        [ 0.9275,  0.9983],\n",
       "        [ 0.9602,  0.9982],\n",
       "        [ 0.9833,  0.9981],\n",
       "        [ 0.9965,  0.9981],\n",
       "        [ 0.9999,  0.9980],\n",
       "        [ 0.9932,  0.9980],\n",
       "        [ 0.9766,  0.9979],\n",
       "        [ 0.9502,  0.9978],\n",
       "        [ 0.9144,  0.9978],\n",
       "        [ 0.8694,  0.9977],\n",
       "        [ 0.8157,  0.9976],\n",
       "        [ 0.7539,  0.9976],\n",
       "        [ 0.6845,  0.9975],\n",
       "        [ 0.6084,  0.9974],\n",
       "        [ 0.5261,  0.9973],\n",
       "        [ 0.4385,  0.9973],\n",
       "        [ 0.3466,  0.9972],\n",
       "        [ 0.2513,  0.9971],\n",
       "        [ 0.1534,  0.9970],\n",
       "        [ 0.0540,  0.9970],\n",
       "        [-0.0460,  0.9969],\n",
       "        [-0.1455,  0.9968],\n",
       "        [-0.2435,  0.9967],\n",
       "        [-0.3392,  0.9966],\n",
       "        [-0.4314,  0.9966],\n",
       "        [-0.5193,  0.9965],\n",
       "        [-0.6020,  0.9964],\n",
       "        [-0.6787,  0.9963],\n",
       "        [-0.7486,  0.9962],\n",
       "        [-0.8111,  0.9961],\n",
       "        [-0.8654,  0.9960],\n",
       "        [-0.9111,  0.9960],\n",
       "        [-0.9477,  0.9959],\n",
       "        [-0.9748,  0.9958],\n",
       "        [-0.9922,  0.9957],\n",
       "        [-0.9997,  0.9956],\n",
       "        [-0.9972,  0.9955],\n",
       "        [-0.9847,  0.9954],\n",
       "        [-0.9624,  0.9953],\n",
       "        [-0.9304,  0.9952],\n",
       "        [-0.8892,  0.9951]])"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "f9770161",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 10000\n",
    "d_k = 4\n",
    "max_seq_len = 100\n",
    "batch_size = 2\n",
    "seq_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c956a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2, 3, 4]), torch.Size([2, 3])]"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [\n",
    "        [1,2,3,4],\n",
    "        [5,6,7,8],\n",
    "        [9,10,11,12]\n",
    "    ],\n",
    "    [\n",
    "        [11,12,13,14],\n",
    "        [15,16,17,18],\n",
    "        [19,20,21,22]\n",
    "    ]\n",
    "]\n",
    "x = torch.tensor(data)\n",
    "data = [\n",
    "    [0,1,2],\n",
    "    [2,0,1]\n",
    "]\n",
    "position = torch.tensor(data)\n",
    "[x.shape, position.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "94bbc1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True]"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape[:-1]==position.shape[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e58048",
   "metadata": {},
   "source": [
    "# Q 3.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "6b29a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: torch.Tensor, dim: int) -> torch.Tensor:\n",
    "    x_max = torch.max(x, dim=dim, keepdim=True).values\n",
    "    x_subtract_max = x-x_max\n",
    "    x_subtract_max_exp = torch.exp(x_subtract_max)\n",
    "    x_subtract_max_exp_sum = torch.sum(x_subtract_max_exp, dim=dim, keepdim=True)\n",
    "    y = x_subtract_max_exp/x_subtract_max_exp_sum\n",
    "    return y\n",
    "\n",
    "def _softmax_1dim(x: torch.Tensor) -> torch.Tensor:\n",
    "    x_subtract_max = x-x.max()\n",
    "    x_subtract_max_exp = torch.exp(x_subtract_max)\n",
    "    return x_subtract_max_exp/x_subtract_max_exp.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "007acdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [\n",
    "        [1,2,3,4],\n",
    "        [5,6,7,8],\n",
    "        [9,10,11,12]\n",
    "    ],\n",
    "    [\n",
    "        [11,12,13,14],\n",
    "        [15,16,17,18],\n",
    "        [19,110,111,112]\n",
    "    ]\n",
    "]\n",
    "x = torch.tensor(data)\n",
    "dim = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "1ff51ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [3.4348e-05, 4.2039e-44, 3.7835e-44, 3.7835e-44]],\n",
       "\n",
       "        [[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
       "         [9.9997e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00]]])"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max = torch.max(x, dim=dim, keepdim=True).values\n",
    "x_subtract_max = x-x.max()\n",
    "x_subtract_max_exp = torch.exp(x_subtract_max)\n",
    "x_subtract_max_exp_sum = torch.sum(x_subtract_max_exp, dim=dim, keepdim=True)\n",
    "x_subtract_max_exp/x_subtract_max_exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "5dfd0041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.4013e-44, 3.7835e-44, 1.0089e-43, 2.7465e-43],\n",
       "         [7.4689e-43, 2.0305e-42, 5.5211e-42, 1.5008e-41],\n",
       "         [4.0797e-41, 1.3534e-01, 3.6788e-01, 1.0000e+00]]])"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_subtract_max_exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(\n",
    "    Q: torch.Tensor,\n",
    "    K: torch.Tensor,\n",
    "    V: torch.Tensor,\n",
    "    mask: torch.Tensor | None = None,\n",
    ") -> torch.Tensor:\n",
    "    d_k = Q.shape[-1]\n",
    "    QK = einsum(\n",
    "        Q, K, \"... n d_k, ... m d_k -> ... n m\"\n",
    "    )\n",
    "    QK_scaled = QK/torch.tensor(d_k).sqrt()\n",
    "    if mask is not None:\n",
    "        M = torch.where(mask, torch.tensor(0.0), torch.tensor(float('-inf')))\n",
    "        QK_scaled += M\n",
    "    QK_scaled_softmax = softmax(QK_scaled, Q.dim()-1)\n",
    "    y = einsum(\n",
    "        QK_scaled_softmax, V, \"... n m, ... m d_v -> ... n d_v\"\n",
    "    )\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "58a85a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 1\n",
    "head = 1\n",
    "n = 3\n",
    "m = 4\n",
    "d_k = 8\n",
    "d_v = 6\n",
    "\n",
    "\n",
    "# 构造 q, k, v：每个维度是 (batch * head, seq, d)\n",
    "q = torch.randn(batch * head, n, d_k)\n",
    "k = torch.randn(batch * head, m, d_k)\n",
    "v = torch.randn(batch * head, m, d_v)\n",
    "\n",
    "# 构造 mask: (batch * head, query_len, key_len)\n",
    "mask = torch.randint(0, 2, (batch * head, n, m)).float()\n",
    "\n",
    "# reshape 到标准的 attention 输入格式\n",
    "Q, K, V = (rearrange(x, \"(batch head) seq d -> batch head seq d\", head=head) for x in (q, k, v))\n",
    "mask = rearrange(mask, \"(batch head) query key -> batch head query key\", head=head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "331e9c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1039,  0.6112, -0.5392, -0.1096,  0.3800, -1.3136],\n",
       "          [ 0.2571,  1.3238,  0.3052,  0.6354,  0.9631, -0.6820],\n",
       "          [ 0.1931,  1.1706,  0.1135,  0.5356,  0.8351, -0.8478]]]])"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = Q.shape[-1]\n",
    "QK = einsum(\n",
    "    Q, K, \"... n d_k, ... m d_k -> ... n m\"\n",
    ")\n",
    "QK_scaled = QK/np.sqrt(d_k)\n",
    "QK_scaled_masked = QK_scaled # + mask*torch.tensor(float('-inf')) \n",
    "QK_scaled_masked_softmax = softmax(QK_scaled_masked, Q.dim()-1)\n",
    "y = einsum(\n",
    "    QK_scaled_masked_softmax, V, \"... n m, ... m d_v -> ... n d_v\"\n",
    ")\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "72958af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.3037, -0.1392,  1.5195,  1.0188],\n",
       "          [ 0.1006, -2.0256, -2.0816,  0.9052],\n",
       "          [ 0.6530, -0.7269,  0.1320,  1.6333]]]])"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QK_scaled_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "4dc00219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0825, 0.0972, 0.5107, 0.3096],\n",
       "          [0.2883, 0.0344, 0.0325, 0.6447],\n",
       "          [0.2217, 0.0558, 0.1317, 0.5909]]]])"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QK_scaled_masked_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "380f6f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([2, 2, 3, 4]), torch.Size([2, 2, 3, 4])]"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[QK_scaled.shape,mask.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9f73a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stanford",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
